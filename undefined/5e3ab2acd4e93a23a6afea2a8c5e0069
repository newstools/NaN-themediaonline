AI is the dominant topic of my inbox, and probably yours as well. I’m extremely excited about it because of the impact it can have on productivity. But I also completely understand the concerns people have, as it is going to make it even easier for disinformation to be spread. And then there’s the question: What is the role the media will have in this new age of AI? The media exists to share information and influence people in a way that is, or should be, based on facts.  Yet we all know too well that the internet created a new, broader form of media that enables and even encourages self-publishing. The voice of the few can sometimes outweigh the voice of the many, and this is even more true when you factor in the primary currency of today’s media as impressions and reach. Media is about aggregating eyeballs, and controversy creates more opportunity for eyeballs driven by emotion. AI creates realistic images, topics and stories that may not be true. For example. the Pope is not wearing a white puffy coat to go out to dinner. That was harmless, but more recently there are examples of AI stories that are false and harmful. And OpenAI is being sued for some of these because it owns the AI. The internet already perpetuates all kinds of false information, mostly because fringe elements are crafting narratives that prey on people’s fears or lack of education and the ability to think critically. The rapid expansion of AI means that it becomes even easier to craft and share these false narratives, and accompany them with deep-fake imagery, and even video, that is almost impossible to differentiate from the truth. How can human beings be expected to differentiate what’s real from what’s not? This is where the media comes in. I believe the growth of AI signals an opportunity for the media to come together and create a system of checks and balances. Media will always look for the chance to break the news, but once news is broken, the facts should be shared, checked and validated across multiple channels so the audience knows these are real and not derived from AI or other tools. This type of industrywide checks and balance would mean that false narratives could not be perpetuated beyond a step or two. And any media outlet perpetuating those false narratives would be called into question whenever they break something, citing a lack of validation based on their past history. I would hope this cross-publication validation system would welcome both sides of the news spectrum, right and left, and actually foster more collaboration in the middle, where most of us actually reside. The media industry has a unique opportunity here. AI could be used to irreparably injure the average person’s trust in media, I fear – if they don’t look to address it. If we can’t feel comfortable trusting some of what we see, how can we be comfortable trusting ANY of what we see? I think people are fundamentally good, and we can figure out how to use the AI for better, and not for worse. This story was first published by MediaPost.com and is republished with the author’s permission. Cory Treffiletti is SVP at FIS. He has been a thought leader, executive and business driver in the digital media landscape since 1994. In addition to authoring a weekly column on digital media, advertising and marketing since 2000 for MediaPost‘s Online Spin, Treffiletti has been a successful executive, media expert and/or founding team member for a number of companies, and published a book, Internet Ad Pioneers, in 2012. 